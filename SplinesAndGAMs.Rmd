---
title: "SplinesAndGAMs"
output: html_document
---


```{r}
rm(list = ls())
library(ISLR)
library(splines)
attach(Wage)
```


Splines
-------

Splines are similar to polynomials - here we'll work on cubic splines

```{r}
fit = lm(wage ~ bs(age, knots = c(25, 40, 60)), data = Wage)
agelims = range(age)
age.grid = seq(from = agelims[1], to = agelims[2])

plot(age, wage, col='darkgrey')
lines(age.grid, 
      predict(fit, list(age = age.grid)),
      col = 'darkgreen',
      lwd = 2)
abline(v=c(25, 40, 60), lty = 2, col = 'darkgreen')
```
the bs function, by default gives you a basis for cubic splines

abline puts vertical lines in the positions indicated. h = would do horizontal lines.



OK, now for smoothing splines

For these you don't define knots, but instead it does have a roughness penalty to make sure that the function doesn't wobble too much.
One way of determining just how smooth is to give it a limit on the 'effective' degrees of freedom that are allowed.

```{r}
fit = smooth.spline(age,wage,df=16)
lines(fit, col='red', lwd=2)
```

The alternative method is to use LOOCV to choose the roughness pararmeter, lambda. Fortunately, there's an argument to do this automatically within the smooth.spline function

```{r}
fit = smooth.spline(age, wage, cv=TRUE)
lines(fit, col='purple', lwd=2)
fit
```

the first line, fitting the spline gives a warning, but that's O in this case. It's because we have lots of people with the same age.

This one found that 6.79 was the optimal effective degrees of freedom (they don't have to be integers when dealing with splines)

In fact, the first spline wtih three knots also fit a function with 6 degrees of freedom.

moving on...



Generalized Additive Models
---------------------------

It can be useful to think of each predictor working on the data in it's own unique way and then combining to produce the output (wage in this case) that we see.

We're going to work with the gam package which knows how to plot these models with their standard errors

```{r fig.width = 10, fig.height=5}
require(gam)
gam1 = gam(wage ~ s(age,df=4) + s(year, df=4) + education, data = Wage)
par(mfrow=c(1,3))
plot(gam1,se=T)
```

s is a special function within gam that knows that you want a smoothing spline over that predictor with that many degrees of freedom

se=T is short hand for TRUE


gam also works for logistic regression

```{r}
gam2 = gam(I(wage>250) ~ s(age, df=4) + s(year, df=4) + education,
           data = Wage,
           family = binomial)
plot(gam2)
```

These graphs show the contribution of the logit to the probability of each of the three predictors. Note this is not the probability, you'd need to use the inverse logit function to find that - the polynomials lesson has details.


At the moment we've got a smooth term for year, but maybe a linear term would work pretty well. Let's have a look.

```{r}
gam2a = gam(I(wage>250) ~ s(age, df=4) + year + education,
            data = Wage,
            family = binomial)
plot(gam2a)
anova(gam2, gam2a, test='Chisq')
```

Because the anova test shows that the chi squared probability is very high, that suggests that they're pretty equivalent, no substantial difference, so may as well just go for the simpler linear term. (maybe year isn't even that informative and could be dropped...)

You can also use plot.gam to plot normal models that you've created. Afterall, it has all the necessary info (model and data). Here's we're using natural splines to model age and year.

```{r fig.width=10 fig.height=5}
par(mfrow = c(1,3))
lm1 = lm(wage ~ ns(age,df=4) + ns(year,df=4) + education, data=Wage)
plot.gam(lm1, se=T)
```






